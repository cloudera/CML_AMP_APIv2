{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4077dfa7",
   "metadata": {},
   "source": [
    "# CML API Example Notebook\n",
    "\n",
    "This notebook demonstrates the core functionality of the CML API. It uses the CML API Python client to make requests to the API service and operate on the responses.\n",
    "\n",
    "Running this notebook will create and delete projects and jobs. It will launch job runs, applications, and model deployments. If the notebook terminates before completing all the cells, some resources may linger and need to be manually terminated/removed. Rerunning cells that create resources may lead to additional resources being created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547cf050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install cmlapi package\n",
    "try:\n",
    "    import cmlapi\n",
    "except ModuleNotFoundError:\n",
    "    import os\n",
    "    cluster = os.getenv(\"CDSW_API_URL\")[:-1]+\"2\"\n",
    "    !pip3 install {cluster}/python.tar.gz\n",
    "    import cmlapi\n",
    "\n",
    "from cmlapi.utils import Cursor\n",
    "import string\n",
    "import random\n",
    "import json\n",
    "\n",
    "try:\n",
    "    client = cmlapi.default_client()\n",
    "except ValueError:\n",
    "    print(\"Could not create a client. If this code is not being run in a CML session, please include the keyword arguments \\\"url\\\" and \\\"cml_api_key\\\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f945f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = \"\".join([random.choice(string.ascii_lowercase) for _ in range(6)])\n",
    "session_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46488a86",
   "metadata": {},
   "source": [
    "## Note\n",
    "- In addition to using python client, **_curl_** is also supported.  \n",
    "`> curl -X GET -H \"Authorization: Bearer ${APIKEY}\" \"https://${CML_DOMAIN}/api/v2/projects\" | python -m json.tool`\n",
    "\n",
    "- The returned objects are _not_ Python dictionaries, so you can't use `object[field]` to reference the fields of the response. Instead, you can use `object.field` to reference the properties of response objects.\n",
    "\n",
    "- All the list_XXX endpoints share the same arguments, particularly search_filter and sort. Examples are provided in [**list_projects**](#list_projects).\n",
    "\n",
    "- In the following examples, we will use legacy engines. However, the usage of legacy engines is similar to the usage of runtimes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fdd6bb",
   "metadata": {},
   "source": [
    "## Create Project\n",
    "- CreateProjectRequest\n",
    "\n",
    "Argument | Type | Description | Notes\n",
    "------------ | ------------- | ------------- | -------------\n",
    "**name** | **str** | The name of the project to create. | \n",
    "**description** | **str** | The description of the project. | \\[optional\\] \n",
    "**visibility** | **str** | The visibility of the project (one of &quot;public&quot;, &quot;organization&quot;, &quot;private&quot;). Default is private. | \\[optional\\] \n",
    "**parent_project** | **str** | Optional parent project to fork. | \\[optional\\] \n",
    "**git_url** | **str** | Optional git URL to checkout for this project. | \\[optional\\] \n",
    "**template** | **str** | Optional template to use (Python, R, PySpark, Scala, Churn Predictor, local, git, blank) Note: local will create the project but nothing else, files must be uploaded separately. |\n",
    "**organization_permission** | **str** | If this is an organization-wide project, the visibility to others in the organization. | \\[optional\\] \n",
    "**default_project_engine_type** | **str** | Whether this project uses legacy engines or runtimes. Valid values are &quot;ml_runtime&quot;, &quot;legacy_engine&quot;, or leave blank to default to the site-wide default. | \\[optional\\]\n",
    "**environment** | **dict(str, str)** | The default set of environment variables to run | \\[optional\\] \n",
    "**shared_memory_limit** | **int** | Additional shared memory limit that engines in this project should have, in MB (default 64). | \\[optional\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = cmlapi.CreateProjectRequest(\n",
    "    name = \"demo_\"+session_id,\n",
    "    description = \"A demo project created using the CML public API\",\n",
    "    default_project_engine_type = \"ml_runtime\",\n",
    "    template = \"Python\")\n",
    "# Create the project\n",
    "project = client.create_project(body)\n",
    "project_id = project.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd22cd6",
   "metadata": {},
   "source": [
    "<a id='list_projects'></a>\n",
    "## List/Get Project\n",
    "The list_projects API call takes the following parameters:\n",
    "\n",
    "Argument | Type | Description  | Notes\n",
    "------------- | ------------- | ------------- | -------------\n",
    " **search_filter** | **str**| Search filter is an optional HTTP parameter to filter results by. Supported search filter keys are: \\[creator.email creator.name creator.username description name owner.email owner.name owner.username\\]. For example:   search_filter={\"name\":\"foo\",\"creator.name\":\"bar\"},. | [optional] \n",
    " **sort** | **str**| Sort is an optional HTTP parameter to sort results by. Supported sort keys are: \\[created_at creator.email creator.name creator.username description name owner.email owner.name owner.username updated_at\\]. where \\&quot;+\\&quot; means sort by ascending order, and \\&quot;-\\&quot; means sort by descending order. For example:   sort&#x3D;-updated_at,+name. | [optional] \n",
    " **page_size** | **int**| Page size is an optional argument for number of entries to return in one page. If not specified, the server will determine a page size. If specified, must be respecified for further requests when using the provided next page token in the response. | [optional] \n",
    " **page_token** | **str**| Page token is an optional argument for specifying which page of results to get. If not specified, the first page will be returned, including a token for the next page. Will be empty if there is no next page. | [optional] \n",
    " **include_public_projects** | **bool**| Default is false. If include_public_projects is set to true, then it will return all projects user has access to, including public projects. | [optional] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List projects using the default sort and default page size (10)\n",
    "client.list_projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae8661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can add search filters for project fields to filter for projects that have the filter present in the specified field. The following will filter for projects whose names contain the word \"demo\".\n",
    "search_filters = {\n",
    "    \"name\": \"demo\",\n",
    "}\n",
    "\n",
    "# List 5 projects that the user has direct read access to (not including general public projects or organization-level projects that the user does not have a specific permission for), sorted ascendingly by when they were updated.\n",
    "projects_list = client.list_projects(\n",
    "    page_size = 5,\n",
    "    search_filter = json.dumps(search_filters),\n",
    "    sort=\"updated_at\"\n",
    ")\n",
    "projects_list\n",
    "# If there are more than 5 such projects, fetch the next 5 using the page_token. The same keyword parameters MUST be included.\n",
    "if projects_list.next_page_token != \"\":\n",
    "    next_page_projects_list = client.list_projects(\n",
    "    page_size = 5,\n",
    "    search_filter = json.dumps(search_filters),\n",
    "    sort=\"updated_at\",\n",
    "    page_token = projects_list.next_page_token\n",
    ")\n",
    "# Fetch the first 5 projects sorted by updated_at in descending order.\n",
    "client.list_projects(\n",
    "    page_size = 5,\n",
    "    search_filter = json.dumps(search_filters),\n",
    "    sort=\"-updated_at\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8be77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get a specific project given its ID.\n",
    "client.get_project(project_id = project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcb11db",
   "metadata": {},
   "source": [
    "## Update project\n",
    "\n",
    "The following project fields can be updated.\n",
    " - name\n",
    " - description\n",
    " - project_visibility\n",
    " - default_project_engine_type\n",
    " - shared_memory_limit\n",
    " - environment\n",
    "\n",
    "The update can be provided as a Project object with the updated fields set to their new values and all other fields set to None, or as a dictionary mapping each field to its new value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942bcf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_body = cmlapi.Project(\n",
    "    name = \"updated_\" + project.name,\n",
    "    visibility = \"public\"\n",
    ")\n",
    "client.update_project(update_body, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc360f35",
   "metadata": {},
   "source": [
    "## List Runtimes\n",
    "When using runtimes, you need to specify which runtime to use. You can list out runtimes to get their identifiers, and include one in your request to use it. You can ignore the field if you are using legacy engines.\n",
    "\n",
    "Like projects, runtimes can be filtered. You can filter runtimes on the following fields:\n",
    "- image_identifier\n",
    "- editor\n",
    "- kernel\n",
    "- edition\n",
    "- description\n",
    "- full_version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_runtimes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277c543-de53-4e8b-866d-62dc682499a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on Standard edition Python 3.9 runtimes using the Workbench editor\n",
    "py39_standard_runtimes = client.list_runtimes(search_filter=json.dumps({\n",
    "     \"kernel\": \"Python 3.9\",\n",
    "     \"edition\": \"Standard\",\n",
    "    \"editor\" : \"Workbench\"\n",
    "}))\n",
    "\n",
    "print(py39_standard_runtimes)\n",
    "\n",
    "# save image identifier for later\n",
    "py39_standard_runtime_image_identifier = py39_standard_runtimes.runtimes[0].image_identifier\n",
    "print(\"Image identifier of the selected Python 3.9 Standard runtime: \", py39_standard_runtime_image_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92f0bbe",
   "metadata": {},
   "source": [
    "## Cursor helper\n",
    "This helper works for any endpoint with _list_ (list_projects, list_jobs, list_runtimes, ...)\n",
    "\n",
    "Cursor returns an iterable objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor also supports search_filter\n",
    "# cursor = Cursor(client.list_runtimes, \n",
    "#                 search_filter = json.dumps({\"image_identifier\":\"jupyter\"}))\n",
    "cursor = Cursor(client.list_runtimes)\n",
    "runtimes = cursor.items()\n",
    "for rt in runtimes:\n",
    "    print(rt.image_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf6603",
   "metadata": {},
   "source": [
    "## Create Job\n",
    "#### CreateJobRequest\n",
    "\n",
    "Argument | Type | Description | Notes\n",
    "------------ | ------------- | ------------- | -------------\n",
    "**project_id** | **str** | ID of the project containing the job. |\n",
    "**name** | **str** | Name of the new job. | \n",
    "**script** | **str** | The script to run for the new job. | \n",
    "**cpu** | **float** | CPU cores to allocate to job runs for this job (default 1). | \\[optional\\] \n",
    "**memory** | **float** | Memory in GB to allocate to job runs for this job (default 1). | \\[optional\\] \n",
    "**nvidia_gpu** | **int** | Number of Nvidia GPUs to allocate to this job (default 0). | \\[optional\\] \n",
    "**parent_job_id** | **str** | Optional dependent job if this new job is a dependency. Setting this to a parent job will make this job run when the parent job completes. Cannot be used alongside \\&quot;schedule\\&quot;. | \\[optional\\] \n",
    "**environment** | **dict(str, str)** | Default environment variables to include in job runs for this job. | \\[optional\\] \n",
    "**arguments** | **str** |  | \\[optional\\] \n",
    "**timeout** | **int** | Timeout in seconds of job runs for this job. | \\[optional\\] \n",
    "**schedule** | **str** | Schedule to run a job automatically. Cannot be used in a dependency job. Follows the cron format. For example, to execute the job every Monday at 1 PM UTC, the schedule would be \\&quot;0 13 * * 1\\&quot; without quotes. | \\[optional\\] \n",
    "**kernel** | **str** | Kernel to run the job runs on. Possible values are python3, python2, r, or scala. Should not be set if the project uses ML Runtimes. | \\[optional\\] \n",
    "**recipients** | **list\\[JobRecipient\\]** | An optional list of recipients to receive notifications for job events such as successful runs, failures, and manual stops. | \\[optional\\] \n",
    "**attachments** | **list\\[str\\]** | Files to attach (with path relative to /home/cdsw/) in notification emails. For example, to attach a file located at /home/cdsw/report/result.csv, include \\&quot;report/result.csv\\&quot; in the array for this field. | \\[optional\\] \n",
    "**runtime_identifier** | **str** | The runtime image identifier to use if this job is part of a ML Runtime project. Must be set if using ML Runtimes. | \\[optional\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b8cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a job. We will create dependent/children jobs of this job, so we call this one a \"grandparent job\". The parameter \"runtime_identifier\" is needed if this is running in a runtimes project.\n",
    "grandparent_job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project_id,\n",
    "    name = \"grandparentJob\",\n",
    "    script = \"analysis.py\",\n",
    "    runtime_identifier = py39_standard_runtime_image_identifier,\n",
    ")\n",
    "# Create this job within the project specified by the project_id parameter.\n",
    "grandparent_job = client.create_job(grandparent_job_body, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c9c0d",
   "metadata": {},
   "source": [
    "### Create dependent jobs\n",
    "When a parent job is started, its child/dependent jobs  will automatically start after it successfully completes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4040728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dependent job by specifying the parent job's ID in the parent_job_id field.\n",
    "parent_job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project_id,\n",
    "    name = \"parentJob\",\n",
    "    script = \"analysis.py\",\n",
    "    runtime_identifier = py39_standard_runtime_image_identifier,\n",
    "    parent_job_id = grandparent_job.id\n",
    ")\n",
    "parent_job = client.create_job(parent_job_body, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f873c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a job that is dependent on the job from the previous cell. This leads to a dependency chain of grandparent_job -> parent_job -> child_job. If grantparent_job runs and succeeds, then parent_job will trigger, and if parent_job runs and succeeds, child_job will trigger. This one uses a template script that does not terminate, so we'll have the opportunity to try stopping it later.\n",
    "child_job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project_id,\n",
    "    name = \"childJob\",\n",
    "    script = \"entry.py\",\n",
    "    runtime_identifier = py39_standard_runtime_image_identifier,\n",
    "    parent_job_id = parent_job.id\n",
    ")\n",
    "child_job = client.create_job(child_job_body, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c790db32",
   "metadata": {},
   "source": [
    "## List/Get Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62217234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will list jobs in the project. By default it will list the first 10, and provide a next_page_token to list more if there are any. This behavior can be controlled by adding the keyword argument \"page_size\".\n",
    "joblists = client.list_jobs(project_id = project_id)\n",
    "print(f'Fetched {len(joblists.jobs)} jobs from the project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e7db13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get a specific job given the project and job ID.\n",
    "client.get_job(project_id = project_id, job_id = parent_job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c51a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all parent jobs \n",
    "curJob = child_job.id\n",
    "while len(curJob)>0:\n",
    "    job = client.get_job(project_id = project_id, job_id = curJob)\n",
    "    print('Job ID:   {}\\n  name:   {}\\n  script: {}'.format(job.id, job.name, job.script))\n",
    "    curJob = job.parent_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07ca0e8",
   "metadata": {},
   "source": [
    "## Update Job\n",
    "\n",
    "When updating a job, you can modify the following fields.\n",
    "\n",
    "- schedule\n",
    "- parent_id\n",
    "- name\n",
    "- timeout\n",
    "- cpu\n",
    "- memory\n",
    "- nvidia_gpu\n",
    "- environment\n",
    "\n",
    "As with projects, you can submit a modification either with a `cmlapi.Job` object where all fields to be updated are set to their updated value, and all other fields are set to None (their default value when creating a new `cmlapi.Job`). Alternatively you can use a dictionary mapping only the fields that are being updated to their new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9681836",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_body = cmlapi.Job(name = \"updated_\"+ parent_job.name)\n",
    "client.update_job(update_body, project_id, parent_job.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b5f98",
   "metadata": {},
   "source": [
    "## Create JobRun\n",
    "\n",
    "#### CreateJobRunRequest\n",
    "Name | Type | Description | Notes\n",
    "------------ | ------------- | ------------- | -------------\n",
    "**project_id** | **str** | ID of the project containing the job. | \n",
    "**job_id** | **str** | The job ID to create a new job run for. | \n",
    "**environment** | **dict(str, str)** | The environment variables to include in this run. | \\[optional\\] \n",
    "**arguments** | **str** | The custom arguments to the job run | \\[optional\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a job run for the specified job.\n",
    "# If the job has dependent jobs, the dependent jobs will run after the job succeeds.\n",
    "# In this case, the grandparent job will run first, then the parent job, and then the child job, provided each job run succeeds.\n",
    "jobrun_body = cmlapi.CreateJobRunRequest(project_id, grandparent_job.id)\n",
    "job_run = client.create_job_run(jobrun_body, project_id, grandparent_job.id)\n",
    "run_id = job_run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5df971",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690a116",
   "metadata": {},
   "source": [
    "## List/Get JobRun\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f83dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a job run given its ID, as well as the job ID and project ID containing the job run.\n",
    "client.get_job_run(project_id, grandparent_job.id, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f76cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all job runs in a job (pursuant to page_size, default 10).\n",
    "job_runs = client.list_job_runs(project_id, child_job.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4085ce2",
   "metadata": {},
   "source": [
    "## Stop JobRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0098afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stop a job run. This will stop whatever the job run is doing and terminate the engine.\n",
    "# We don't know which job run it's on (since grandparent, parent, and child are all running). So, we will try to stop all of them, and ignore errors that arise if they are already stopped.\n",
    "# Since each job can only have at most one active run, we only need to check the most recent job run for each job.\n",
    "for job in [grandparent_job, parent_job, child_job]:\n",
    "    job_runs = client.list_job_runs(project_id, job.id, sort=\"-created_at\", page_size=1)\n",
    "    if len(job_runs.job_runs) == 1:\n",
    "        job_run = job_runs.job_runs[0]\n",
    "        try:\n",
    "            client.stop_job_run(project_id, child_job.id, job_run.id)\n",
    "        except cmlapi.rest.ApiException:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819c3c07",
   "metadata": {},
   "source": [
    "## Create Application\n",
    "\n",
    "#### CreateApplicationRequest\n",
    "Argument | Type | Description | Notes\n",
    "------------ | ------------- | ------------- | -------------\n",
    "**project_id** | **str** | The project's identifier | \n",
    "**name** | **str** | Name of the new application. |  \n",
    "**subdomain** | **str** | The subdomain of the application. The application will be served at the URL http(s)://subdomain.<domain> | \n",
    "**description** | **str** | The description of the application. | [optional] \n",
    "**script** | **str** | The script to run for the new application. | \n",
    "**cpu** | **float** | CPU cores to allocate to application (default 1). | [optional] \n",
    "**memory** | **float** | Memory in GB to allocate to application (default 1). | [optional] \n",
    "**nvidia_gpu** | **int** | Number of Nvidia GPUs to allocate to this application (default 0). | [optional] \n",
    "**environment** | **dict(str, str)** | Default environment variables to include in application. | [optional] \n",
    "**kernel** | **str** | Kernel to run the job runs on. Possible values are python3, python2, r, or scala. | [optional] \n",
    "**bypass_authentication** | **bool** | Enable unauthenticated access to application | [optional] \n",
    "\n",
    "Creating application also starts application implicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af13279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a simple application. If using runtimes, the runtime_identifier must be specified.\n",
    "application_request = cmlapi.CreateApplicationRequest(\n",
    "    name = \"demo_app_\"+session_id,\n",
    "    description = \"A sample application to demonstrate CML APIs\",\n",
    "    project_id = project_id,\n",
    "    subdomain = \"demo-\"+session_id,\n",
    "    runtime_identifier = py39_standard_runtime_image_identifier,\n",
    "    script = \"entry.py\",\n",
    ")\n",
    "app = client.create_application(\n",
    "    project_id = project_id,\n",
    "    body = application_request\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bd184e",
   "metadata": {},
   "source": [
    "## List/Get Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bfe209",
   "metadata": {},
   "source": [
    "Applications can be listed using the same mechanisms (sort, search_filter, page_size, etc.) as the other resources we've seen so far. Applications can be filtered on the following properties:\n",
    "- creator.email\n",
    "- creator.name\n",
    "- creator.username\n",
    "- description\n",
    "- full_name\n",
    "- name\n",
    "- script\n",
    "- subdomain\n",
    "- status\n",
    "- kernel\n",
    "- bypass_authentication\n",
    "- runtime_identifier\n",
    "\n",
    "Applications can also be sorted on the following properties:\n",
    "- created_at\n",
    "- creator.email\n",
    "- creator.name\n",
    "- creator.username\n",
    "- description\n",
    "- name\n",
    "- kernel\n",
    "- script\n",
    "- updated_at\n",
    "- status\n",
    "- runtime_identifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can list applications similarly to other resources.\n",
    "client.list_applications(project_id = project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a83b3",
   "metadata": {},
   "source": [
    "## Update Application\n",
    "\n",
    "When updating an application, you can modify the following fields:\n",
    "- name\n",
    "- subdomain\n",
    "- description\n",
    "- script\n",
    "- bypass_authentication\n",
    "- kernel\n",
    "- cpu\n",
    "- memory\n",
    "- nvidia_gpu\n",
    "- environment\n",
    "\n",
    "Modifying these fields can be done similarly to how we updated projects and jobs earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3667db",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_application_req = cmlapi.Application(\n",
    "    name = \"updated_\" + app.name,\n",
    "    subdomain = \"updated-\" + app.subdomain,\n",
    "    description = \"updated_\" + app.description,\n",
    "    environment = json.dumps({\"UPDATED_ENV\": \"UPDATED_ENV_VALUE\"}),\n",
    ")\n",
    "updated_application = client.update_application(\n",
    "    update_application_req,\n",
    "    project_id = project_id,\n",
    "    application_id = app.id\n",
    ")\n",
    "updated_application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b70128",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Deploying a model is a three-step process. First, create a model with some basic information. Second, build the model by specifying the file to use and function to run. Finally, deploy the model with some allocated resources.\n",
    "\n",
    "1. CreateModel\n",
    "\n",
    "#### CreateModelRequest\n",
    "\n",
    "Argument | Type | Description | Notes\n",
    "------------ | ------------- | ------------- | -------------\n",
    "**project_id** | **str** | ID of the project containing the model. |  \n",
    "**name** | **str** | Name of the model. |  \n",
    "**description** | **str** | Description of the model. | \\[optional\\] \n",
    "**disable_authentication** | **bool** | Whether to disable authentication for requests to deployments of this model. | \\[optional\\] \n",
    "\n",
    "2. CreateModelBuild\n",
    "\n",
    "#### CreateModelBuildRequest\n",
    "\n",
    "Argument | Type | Description | Notes\n",
    "------------ | ------------- | ------------- | -------------\n",
    "**project_id** | **str** | ID of the project containing the model build. |\n",
    "**model_id** | **str** | The ID of the model that will the build. | \n",
    "**comment** | **str** | A comment associated with the build. | \\[optional\\] \n",
    "**file_path** | **str** | The path to the file to build. | \n",
    "**function_name** | **str** | The function name to run when executing the build. |  \n",
    "**kernel** | **str** | The kernel the model build should use. | \n",
    "**runtime_identifier** | **str** | The runtime ID the model build should use. | \n",
    "\n",
    "\n",
    "3. CreateModelDeployment\n",
    "\n",
    "#### CreateModelDeploymentRequest\n",
    "\n",
    "Argument | Type | Description | Notes\n",
    "------------ | ------------- | ------------- | -------------\n",
    "**project_id** | **str** | ID of the project containing the model. | \n",
    "**model_id** | **str** | ID of the model to deploy. | \n",
    "**build_id** | **str** | ID of the model build to deploy. | \n",
    "**cpu** | **float** | Number of vCPU to allocate to the deployment. | \\[optional\\] \n",
    "**memory** | **float** | Amount of memory in GB to allocate to the deployment. | \\[optional\\] \n",
    "**nvidia_gpus** | **int** | Number of nvidia GPUs to allocate to the deployment. | \\[optional\\] \n",
    "**environment** | **dict(str, str)** | Environment variables to run the deployment with. | \\[optional\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae491d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelReq = cmlapi.CreateModelRequest(\n",
    "    name = \"demo-model-\" + session_id,\n",
    "    description = \"model created for demo\",\n",
    "    project_id = project_id,\n",
    ")\n",
    "model = client.create_model(modelReq, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a09bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_build_request = cmlapi.CreateModelBuildRequest(\n",
    "    project_id = project_id,\n",
    "    model_id = model.id,\n",
    "    comment = \"test comment\",\n",
    "    file_path = \"pi.py\",\n",
    "    function_name = \"predict\",\n",
    "    runtime_identifier = py39_standard_runtime_image_identifier,\n",
    ")\n",
    "modelBuild = client.create_model_build(\n",
    "    model_build_request, project_id, model.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f670f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deployment = cmlapi.CreateModelDeploymentRequest(\n",
    "        project_id = project_id, \n",
    "        model_id = model.id, \n",
    "        build_id = modelBuild.id\n",
    "    )\n",
    "model_deployment_response = client.create_model_deployment(\n",
    "        model_deployment, \n",
    "        project_id = project_id, \n",
    "        model_id = model.id, \n",
    "        build_id = modelBuild.id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9163b2e",
   "metadata": {},
   "source": [
    "## Get/List models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77016148",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_model(project_id = project_id, model_id = model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5bfbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_models(project_id = project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e5fd50",
   "metadata": {},
   "source": [
    "## Get/List model_builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39336ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_model_build(\n",
    "    project_id = project_id,\n",
    "    model_id = model.id,\n",
    "    build_id = modelBuild.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_model_builds(project_id = project_id, model_id = model.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13282600",
   "metadata": {},
   "source": [
    "## Get/List model_deployments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da75a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_model_deployment(project_id = project_id, model_id = model.id, build_id = modelBuild.id, deployment_id=model_deployment_response.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12276d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_model_deployments(\n",
    "    project_id = project_id,\n",
    "    model_id = model.id,\n",
    "    build_id = modelBuild.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5869c3",
   "metadata": {},
   "source": [
    "## Stop model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.stop_model_deployment(\n",
    "    project_id = project_id,\n",
    "    model_id = model.id,\n",
    "    build_id = modelBuild.id,\n",
    "    deployment_id = model_deployment_response.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e9809a",
   "metadata": {},
   "source": [
    "## Deleting resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting job does not delete its dependent jobs\n",
    "client.delete_job(project_id = project_id, job_id = parent_job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d91679",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_application(project_id = project_id, application_id = app.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2374a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines to delete the project\n",
    "# client.delete_project(project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2cd56f",
   "metadata": {},
   "source": [
    "**_If this documentation includes code, including but not limited to, code examples, Cloudera makes this available to you under the terms of the Apache License, Version 2.0, including any required notices. A copy of the Apache License Version 2.0 can be found in LICENSE.txt of this repository._**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
